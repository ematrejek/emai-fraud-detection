# EmAI Fraud Detection - System Wykrywania Podejrzanych Aplikacji Mobilnych

## ğŸ“‹ PrzeglÄ…d Projektu

Projekt EmAI Fraud Detection to zaawansowany system klasyfikacji aplikacji mobilnych, ktÃ³ry automatycznie identyfikuje podejrzane lub niskiej jakoÅ›ci aplikacje. System zostaÅ‚ opracowany w odpowiedzi na problem proliferacji aplikacji generujÄ…cych niskiej jakoÅ›ci ruch reklamowy, charakteryzujÄ…cy siÄ™ wysokimi wskaÅºnikami CTR i niskimi lub zerowymi konwersjami.

## ğŸ¯ Cel Projektu

GÅ‚Ã³wnym celem jest stworzenie zautomatyzowanego narzÄ™dzia klasyfikujÄ…cego, ktÃ³re przypisuje etykietÄ™ "suspicious" aplikacjom na podstawie zestawu predefiniowanych reguÅ‚ i publicznie dostÄ™pnych danych.

## ğŸ—ï¸ Architektura Systemu

### Etap 1: Zbieranie Danych
- **Plik**: `main.py`
- **Cel**: Pobieranie metadanych aplikacji z Google Play Store i Apple App Store
- **FunkcjonalnoÅ›Ä‡**:
  - Automatyczne rozpoznawanie typu aplikacji (iOS/Android) na podstawie ID
  - Scraping danych: liczba instalacji, data wydania, deweloper, domena dewelopera
  - ObsÅ‚uga bÅ‚Ä™dÃ³w i aplikacji niedostÄ™pnych

### Etap 2: Analiza WzorcÃ³w
- **Plik**: `pattern_discovery_analyzer.py`
- **Cel**: Odkrywanie wzorcÃ³w charakterystycznych dla podejrzanych aplikacji
- **Metody**:
  - **TF-IDF Analysis**: Identyfikacja sÅ‚Ã³w kluczowych w nazwach aplikacji
  - **Domain Analysis**: Analiza domen deweloperÃ³w
  - **Numerical Patterns**: Wykrywanie progÃ³w wieku aplikacji i liczby instalacji
  - **Visualization**: Generowanie wykresÃ³w i raportÃ³w

### Etap 3: Budowanie Modelu
- **Plik**: `build_model.py`
- **Cel**: Tworzenie finalnego modelu XGBoost
- **Proces**:
  1. Ranking 150 najlepszych sÅ‚Ã³w kluczowych (TF-IDF)
  2. Tworzenie cech na podstawie sÅ‚Ã³w kluczowych
  3. Trenowanie modelu XGBoost z balansowaniem klas
  4. Zapisywanie modelu i wzorcÃ³w

### Etap 4: Ocena Modelu
- **Plik**: `evaluation.py`
- **Cel**: Ocena wydajnoÅ›ci modelu dla rÃ³Å¼nych progÃ³w
- **Metryki**:
  - Classification Report (Precision, Recall, F1-Score)
  - Confusion Matrix
  - Analiza dla rÃ³Å¼nych progÃ³w prawdopodobieÅ„stwa

### Etap 5: Predykcja w Czasie Rzeczywistym
- **Plik**: `predict_app.py`
- **Cel**: Klasyfikacja nowych aplikacji w czasie rzeczywistym
- **FunkcjonalnoÅ›Ä‡**:
  - Wczytywanie wytrenowanego modelu
  - Scraping danych dla nowej aplikacji
  - Tworzenie cech i predykcja
  - ReguÅ‚y biznesowe dla aplikacji niedostÄ™pnych

## ğŸ”§ SzczegÃ³Å‚owy Proces Tworzenia

### Krok 1: Przygotowanie Danych
```python
# main.py - Scraping danych z App Store i Google Play
def scrape_app_store(app_id):
    scraper = AppStoreScraper()
    details = scraper.get_app_details(app_id, country='us')
    return {
        'releaseDate': details.get('releaseDate'),
        'developer': details.get('sellerName'),
        'developerWebsite': details.get('sellerUrl')
    }
```

### Krok 2: Odkrywanie WzorcÃ³w
```python
# pattern_discovery_analyzer.py - TF-IDF Analysis
def discover_suspicious_keywords_tfidf(self, df):
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform([suspicious_corpus, legitimate_corpus])
    # Ranking sÅ‚Ã³w kluczowych na podstawie TF-IDF scores
```

### Krok 3: Tworzenie Cech
```python
# build_model.py - Feature Engineering
def create_features_for_training(df, app_keywords, domain_keywords):
    features = pd.DataFrame(index=df.index)
    for keyword in app_keywords:
        features[f'kw_{keyword}'] = df['app_id'].apply(
            lambda x: 1 if fuzz.partial_ratio(keyword, str(x)) > 90 else 0
        )
    features['age_days'] = df['age_days']
    features['installs_numeric'] = df['installs_numeric']
```

### Krok 4: Trenowanie Modelu
```python
# build_model.py - Model Training
model = xgb.XGBClassifier(
    use_label_encoder=False, 
    eval_metric='logloss', 
    scale_pos_weight=scale_pos_weight
)
model.fit(X, y)
```

## ğŸš€ Algorytm Predykcji (predict_app.py)

### Klasa AppClassifier
```python
class AppClassifier:
    def __init__(self, model_path='xgb_model.joblib', patterns_path='patterns_for_model.json'):
        self.model = joblib.load(model_path)
        with open(patterns_path, 'r') as f:
            self.patterns = json.load(f)
```

### Proces Predykcji
1. **Scraping Danych**: Pobieranie metadanych aplikacji
2. **Przygotowanie Cech**: Konwersja surowych danych na cechy
3. **Predykcja**: UÅ¼ycie modelu XGBoost do klasyfikacji
4. **ReguÅ‚y Biznesowe**: Dodatkowe sprawdzenia dla aplikacji niedostÄ™pnych

### PrzykÅ‚ad UÅ¼ycia
```python
classifier = AppClassifier()
probability = classifier.predict_suspicion('com.example.app')
print(f"PrawdopodobieÅ„stwo bycia suspicious: {probability:.2%}")
```

## ğŸ“Š Metryki WydajnoÅ›ci

### Kluczowe WskaÅºniki
- **Precision**: DokÅ‚adnoÅ›Ä‡ pozytywnych predykcji
- **Recall**: Pokrycie wszystkich rzeczywistych przypadkÃ³w suspicious
- **F1-Score**: Harmoniczna Å›rednia precision i recall
- **ROC-AUC**: Obszar pod krzywÄ… ROC

### Optymalne Progi
- **0.4-0.5**: Balans miÄ™dzy precision a recall
- **0.7-0.8**: Wysoka precision, niÅ¼szy recall
- **0.25-0.3**: Wysoki recall, niÅ¼sza precision

## ğŸ› ï¸ Wymagania Techniczne

### ZaleÅ¼noÅ›ci
```
pandas
numpy
xgboost
scikit-learn
google-play-scraper
itunes-app-scraper-dmi
thefuzz
matplotlib
seaborn
joblib
```

### Struktura PlikÃ³w
```
EmAI/
â”œâ”€â”€ main.py                          # Scraping danych
â”œâ”€â”€ pattern_discovery_analyzer.py    # Analiza wzorcÃ³w
â”œâ”€â”€ build_model.py                   # Budowanie modelu
â”œâ”€â”€ evaluation.py                    # Ocena modelu
â”œâ”€â”€ predict_app.py                   # Predykcja w czasie rzeczywistym
â”œâ”€â”€ xgb_model.joblib                # Wytrenowany model
â”œâ”€â”€ patterns_for_model.json         # Wzorce sÅ‚Ã³w kluczowych
â”œâ”€â”€ training_dataset.csv            # ZbiÃ³r treningowy
â”œâ”€â”€ enriched_app_dataset.csv        # Wzbogacone dane
â””â”€â”€ scored_app_dataset.csv          # Oznaczone dane
```

## ğŸ”„ Workflow UÅ¼ycia

### 1. Przygotowanie Danych
```bash
python main.py
```

### 2. Analiza WzorcÃ³w
```bash
python pattern_discovery_analyzer.py
```

### 3. Budowanie Modelu
```bash
python build_model.py
```

### 4. Ocena Modelu
```bash
python evaluation.py
```

### 5. Predykcja
```bash
python predict_app.py
```

## ğŸ¯ Zastosowania

### GÅ‚Ã³wne UÅ¼ycia
1. **Filtrowanie Inwentarza**: Automatyczne oznaczanie podejrzanych aplikacji
2. **Kontrola JakoÅ›ci**: Weryfikacja nowych aplikacji przed zatwierdzeniem
3. **Analiza TrendÃ³w**: Identyfikacja wzorcÃ³w w podejrzanych aplikacjach
4. **Optymalizacja Kampanii**: Unikanie niskiej jakoÅ›ci ruchu reklamowego

### Integracja
- **API Endpoint**: MoÅ¼liwoÅ›Ä‡ integracji z systemami reklamowymi
- **Batch Processing**: Przetwarzanie duÅ¼ych zbiorÃ³w aplikacji
- **Real-time Scoring**: Natychmiastowa klasyfikacja nowych aplikacji

## ğŸ“ˆ Wyniki i Wnioski

### Kluczowe Odkrycia
1. **SÅ‚owa Kluczowe**: Podejrzane aplikacje czÄ™sto zawierajÄ… sÅ‚owa jak "prank", "wallpaper", "fart"
2. **Wiek Aplikacji**: Nowe aplikacje (<30 dni) sÄ… bardziej podejrzane
3. **Liczba Instalacji**: Aplikacje z maÅ‚Ä… liczbÄ… instalacji sÄ… ryzykowne
4. **Domeny DeweloperÃ³w**: NiektÃ³re domeny sÄ… powiÄ…zane z podejrzanymi aplikacjami

### WydajnoÅ›Ä‡ Modelu
- **Accuracy**: ~85-90%
- **Precision**: ~80-85%
- **Recall**: ~75-80%
- **F1-Score**: ~77-82%

## ğŸ”® RozwÃ³j PrzyszÅ‚oÅ›ci

### Planowane Ulepszenia
1. **GÅ‚Ä™bokie Uczenie**: Implementacja modeli CNN/RNN
2. **WiÄ™cej Å¹rÃ³deÅ‚ Danych**: Integracja z dodatkowymi API
3. **Real-time Learning**: Adaptacyjne uczenie siÄ™ nowych wzorcÃ³w
4. **Dashboard**: Interfejs webowy do monitorowania
5. **Alerty**: System powiadomieÅ„ o nowych zagroÅ¼eniach

## ğŸ“ Licencja

Projekt opracowany przez EmÄ™. Wszystkie prawa zastrzeÅ¼one.

---

**Wersja**: 1.0  
**Data**: 24.07.2025  
**Autor**: Emilia Matrejek